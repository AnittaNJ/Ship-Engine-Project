{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import IsolationForest"
      ],
      "metadata": {
        "id": "IfEIwvkFLyxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URL to import data set.\n",
        "url = ''"
      ],
      "metadata": {
        "id": "mn1_spG2sdfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "DQAwxOsxCUth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "yBKqSxPMM7h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "aE_q5TWrNVme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "vd38XxurwcOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#identifying duplicate values\n",
        "df.duplicated().any()"
      ],
      "metadata": {
        "id": "-LZ8hjfEQRL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#identifying missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "PoAqP09mQ1VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualise correlation heatmap\n",
        "corr_matrix = df.corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2VSMBnJLPy3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descriptive statistics"
      ],
      "metadata": {
        "id": "l-rjIt5huno2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "TtvZUDb8NUSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory data analysis"
      ],
      "metadata": {
        "id": "5kZA4xkGvO65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,10))\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.hist(df['Engine rpm'], bins=20, color='skyblue', edgecolor='black')\n",
        "plt.title('Histogram of Engine rpm')\n",
        "plt.xlabel('Engine rpm')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.hist(df['Lub oil pressure'], bins=20, color='salmon', edgecolor='black')\n",
        "plt.title('Histogram of Lub oil pressure')\n",
        "plt.xlabel('Lub oil pressure')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.hist(df['Fuel pressure'], bins=20, color='lightgreen', edgecolor='black')\n",
        "plt.title('Histogram of Fuel pressure')\n",
        "plt.xlabel('Fuel pressure')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.hist(df['Coolant pressure'], bins=20, color='orange', edgecolor='black')\n",
        "plt.title('Histogram of Coolant pressure')\n",
        "plt.xlabel('Coolant pressure')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.hist(df['lub oil temp'], bins=20, color='purple', edgecolor='black')\n",
        "plt.title('Histogram of Lub oil temp')\n",
        "plt.xlabel('lub oil temp')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.hist(df['Coolant temp'], bins=20, color='lightyellow', edgecolor='black')\n",
        "plt.title('Histogram of Coolant temp')\n",
        "plt.xlabel('Coolant temp')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "anBNNR8BT6yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18, 10))\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.boxplot(df['Engine rpm'])\n",
        "plt.title('Box Plot of Engine rpm')\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.boxplot(df['Lub oil pressure'])\n",
        "plt.title('Box Plot of Lub oil pressure')\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.boxplot(df['Fuel pressure'])\n",
        "plt.title('Box Plot of Fuel pressure')\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.boxplot(df['Coolant pressure'])\n",
        "plt.title('Box Plot of Coolant pressure')\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.boxplot(df['lub oil temp'])\n",
        "plt.title('Box Plot of lub oil temp')\n",
        "\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.boxplot(df['Coolant temp'])\n",
        "plt.title('Box Plot of Coolant temp')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JOAZNR1gbBPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anomaly Detection"
      ],
      "metadata": {
        "id": "HhtXeS57xMYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using interquartile range (IQR) method to identify outliers for each feature."
      ],
      "metadata": {
        "id": "tBqc0yjGxRLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_df = df.copy()"
      ],
      "metadata": {
        "id": "zoD4pKb2T9GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in outlier_df.columns:\n",
        "\n",
        "    Q1 = outlier_df[col].quantile(0.25)\n",
        "    Q3 = outlier_df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    outlier_df[f'Outlier_{col}'] = ((outlier_df[col] < (Q1 - 1.5 * IQR)) | (outlier_df[col] > (Q3 + 1.5 * IQR))).astype(int)\n",
        "\n",
        "outlier_df\n"
      ],
      "metadata": {
        "id": "hirCDbVEgbqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering out samples\n",
        "outliers_count = outlier_df.filter(like='Outlier').sum(axis=1)\n",
        "outlier_df['anomaly'] = (outliers_count >= 2).astype(int)\n",
        "outlier_df"
      ],
      "metadata": {
        "id": "IidVvmbEbPMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier percentage\n",
        "outlier_percentage = (outlier_df['anomaly'].sum()/len(outlier_df))*100\n",
        "outlier_percentage"
      ],
      "metadata": {
        "id": "Xu0c5AqezWI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking samples who have all features under outlier category\n",
        "outlier_df[outliers_count == len(df.columns)]"
      ],
      "metadata": {
        "id": "dMMLZdIocoey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anomaly detection using OneClassSVM"
      ],
      "metadata": {
        "id": "UFnEqUdV2B1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling"
      ],
      "metadata": {
        "id": "cZ42AE3e1ZXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df)\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
        "\n",
        "scaled_df.head()"
      ],
      "metadata": {
        "id": "58Bx5T2qQnsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets apply one-class SVM to the scaled dataframe."
      ],
      "metadata": {
        "id": "N1hw7FTPbdxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = OneClassSVM(kernel='rbf', gamma=0.2, nu=0.03)\n",
        "model.fit(scaled_df)"
      ],
      "metadata": {
        "id": "_5c-hDOs0aw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anomaly = model.predict(scaled_df)\n",
        "anomaly"
      ],
      "metadata": {
        "id": "2BFkHu2dpBA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_df = df.copy()\n",
        "svm_df['anomaly']= anomaly\n",
        "svm_df"
      ],
      "metadata": {
        "id": "S5KNiC8MpMBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Predicting anomalies where '-1' indicates an anomaly and '1' indicates normal behavior.\n",
        "\n"
      ],
      "metadata": {
        "id": "CEbFTIIi2TFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display only anomalies in the DataFrame.\n",
        "only_anomalies = svm_df[svm_df.anomaly == -1]\n",
        "print(only_anomalies.shape)\n",
        "only_anomalies"
      ],
      "metadata": {
        "id": "_Ya7sHhc6yjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier percentage\n",
        "outlier_percentage = ((svm_df['anomaly'] == -1).sum()/len(svm_df))*100\n",
        "outlier_percentage"
      ],
      "metadata": {
        "id": "o5VAoM-b0ax8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df[features].head()"
      ],
      "metadata": {
        "id": "iEFZF2Sas-9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using PCA for dimensionality reduction\n",
        "pca = PCA(n_components = 2)\n",
        "components = pca.fit_transform(scaled_df[features])\n",
        "components[:5]"
      ],
      "metadata": {
        "id": "LaVTVzQ-uReQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating dataframe for PCA model data\n",
        "pca_df = pd.DataFrame(data = components,columns=['pca_1','pca_2'])\n",
        "pca_df.head()"
      ],
      "metadata": {
        "id": "lJbJsQ_Bu71P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for 2D visualisation\n",
        "model = OneClassSVM(kernel='rbf', gamma=0.2, nu=0.03)\n",
        "model.fit(pca_df)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title('Anomaly Detection')\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(-0.8, 0.8, 500), np.linspace(-0.8, 0.8, 500))\n",
        "Z = model.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "y_pred = model.predict(pca_df)\n",
        "\n",
        "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.PuBu, alpha=0.8)\n",
        "plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='darkred')  # Decision boundary\n",
        "plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors='palevioletred', alpha=0.5)\n",
        "\n",
        "sns.scatterplot(x=pca_df['pca_1'], y=pca_df['pca_2'], hue=np.where(y_pred == 1, 'Normal', 'Anomaly'),\n",
        "                    style=np.where(y_pred == -1, 'Anomaly', 'Normal'), markers={'Anomaly': 'X', 'Normal': 'o'},\n",
        "                    palette={'Normal': 'deepskyblue', 'Anomaly': 'red'}, alpha=0.6, edgecolor='k')\n",
        "\n",
        "\n",
        "plt.axis('tight')\n",
        "plt.xlim((-0.8, 0.8))\n",
        "plt.ylim((-0.8, 0.8))\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yMjBUJPExRqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecting anomalies using Isolation Forest algorithm"
      ],
      "metadata": {
        "id": "OLzAOhkJ6T6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iso_forest = IsolationForest(contamination=0.03, random_state=42)\n",
        "iso_forest.fit(scaled_df)"
      ],
      "metadata": {
        "id": "dkjYMv-F1iPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting anomalies\n",
        "outlier = iso_forest.predict(scaled_df)\n",
        "outlier"
      ],
      "metadata": {
        "id": "OwuIhNU55kiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iso_df = df.copy()\n",
        "iso_df['anomaly'] = outlier\n",
        "iso_df"
      ],
      "metadata": {
        "id": "f-24EBaf5qch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "((iso_df['anomaly'] == -1).sum()/len(svm_df))*100"
      ],
      "metadata": {
        "id": "E_UcW8Vf5zLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For visualising the anomalies generated in isolation forest model in 2D, I used PCA model to get 2D data."
      ],
      "metadata": {
        "id": "-ZC9iOZtdNR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pcaiso_forest = IsolationForest(contamination=0.03, random_state=42)\n",
        "pcaiso_forest.fit(pca_df)"
      ],
      "metadata": {
        "id": "vfYqkC4y5gmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outlier = pcaiso_forest.predict(pca_df)\n",
        "outlier"
      ],
      "metadata": {
        "id": "IdFVSfoA3LWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pcaiso_df = df.copy()\n",
        "pcaiso_df['anomaly'] = outlier\n",
        "pcaiso_df"
      ],
      "metadata": {
        "id": "827lCMCS5ntt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display only anomalies in the DataFrame.\n",
        "only_anomalies = pcaiso_df[pcaiso_df.anomaly == -1]\n",
        "print(only_anomalies.shape)\n",
        "only_anomalies"
      ],
      "metadata": {
        "id": "VcBxKIiJ6nTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_df = pd.concat([pca_df,pcaiso_df['anomaly']],axis=1)\n",
        "updated_df"
      ],
      "metadata": {
        "id": "mnvy9mauGDbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualising the output in 2D\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter(updated_df['pca_1'], updated_df['pca_2'], c= updated_df['anomaly'], cmap='coolwarm')\n",
        "plt.title('Isolation Forest Anomaly Detection (2D PCA)')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.colorbar(label='Outlier (1: Normal, -1: Anomaly)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8iX8J7LJOXsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reflect\n",
        "\n",
        "> The objective was to develop a robust anomaly detection system to protect the shipping fleet by evaluating engine functionality. The dataset had six important features to evaluate the engineâ€™s status as good or bad. I decided to follow a structured approach of exploratory data analysis, data preprocessing and anomaly detection using statistical methods like IQR and also using ML models like one-class SVM and Isolation Forest. The 2D visualisation of anomalies by reducing the six features to two using the PCA model will give me a better insight about the distribution of anomalies and normal data behaviour. The visualisation and outputs from the model can then be used to interpret which ships are functioning badly and features that need to be monitored and fixed.\n"
      ],
      "metadata": {
        "id": "yjrtAugN6rBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reference:\n",
        "Devabrat, M., 2022. Predictive Maintenance on Ship's Main Engine using AI. Available at: https://dx.doi.org/10.21227/g3za-v415. [Accessed 5 March 2024]"
      ],
      "metadata": {
        "id": "ggnYxWfMMvuj"
      }
    }
  ]
}